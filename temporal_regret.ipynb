{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 18:30:31.666950: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict, Counter\n",
    "from utils import * \n",
    "import stellargraph as sg\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.data import EdgeSplitter, BiasedRandomWalk, TemporalRandomWalk\n",
    "from scipy.special import softmax\n",
    "from tqdm import tqdm\n",
    "\n",
    "from math import isclose\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing\n",
    "import sklearn.model_selection \n",
    "from gensim.models import Word2Vec\n",
    "# python3 -m pip install tqdm seaborn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CM_Time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class temporalNetwork(): \n",
    "    def __init__(self, start_date, end_date, display_progress=False, location_grouping='kma', origin=None, facility_id=None, intermediate=None):\n",
    "        \"\"\" \n",
    "        Note: \n",
    "            start_date and end_date should be both None as they are used as a signal to \n",
    "            CM_Time's run_simulation to whether construct a new graph or update the graph with new information \n",
    "        \"\"\"\n",
    "        self.display_progress = display_progress\n",
    "        self.start_date=start_date\n",
    "        self.end_date=end_date\n",
    "        self.network=None\n",
    "        self.origin_location_list=None\n",
    "        self.location_grouping=location_grouping\n",
    "        self.inbound_data = None \n",
    "        self.outbound_data = None\n",
    "\n",
    "    def construct_network_graph(self):\n",
    "        \"\"\" \n",
    "        Given an inbound and outbound dataframe, construct a network graph and stores it in the class variable self.network\n",
    "        Args: \n",
    "            an_inbound_df (pd.DataFrame): inbound dataframe\n",
    "            an_outbound_df (pd.DataFrame): outbound dataframe\n",
    "            start_date (datetime): start date of the network graph\n",
    "            end_date (datetime): end date of the network graph\n",
    "            location_grouping(string): 'kma' or 'zip3'\n",
    "        \"\"\"\n",
    "        # pull data & construct an empty multiDiGraph\n",
    "\n",
    "        date = self.start_date.strftime(\"%Y-%m-%d\") + \"_\" + self.end_date.strftime(\"%Y-%m-%d\")\n",
    "        an_inbound_df, an_outbound_df = pd.read_csv(f\"../inbound_data/inbound_data_{date}.csv\"), pd.read_csv(f\"../outbound_data/outbound_data_{date}.csv\")\n",
    "        an_inbound_df.load_date, an_outbound_df.load_date = pd.to_datetime(an_inbound_df.load_date), pd.to_datetime(an_outbound_df.load_date)\n",
    "        for colin, colout in zip(an_inbound_df.columns, an_outbound_df.columns): \n",
    "            if colin not in [\"total_loads\", \"load_date\"]: \n",
    "                an_inbound_df[colin] = an_inbound_df[colin].astype(str)\n",
    "            if colout not in [\"total_loads\", \"load_date\"]:\n",
    "                an_outbound_df[colout] = an_outbound_df[colout].astype(str)\n",
    "\n",
    "        network_graph = nx.MultiDiGraph(name=f\"original network\", start_date=self.start_date, end_date=self.end_date)\n",
    "        # network_graph = nx.DiGraph(name=f\"original network\", start_date=self.start_date, end_date=self.end_date)\n",
    "        # idf, odf = an_inbound_df.copy(), an_outbound_df.copy()\n",
    "\n",
    "        # idf.to_csv(f\"data/inbound_data_{self.start_date}_{self.end_date}.csv\", index=False)\n",
    "        # odf.to_csv(f\"data/outbound_data_{self.start_date}_{self.end_date}.csv\", index=False)\n",
    "\n",
    "        # add nodes & edges \n",
    "        node_1 = f\"origin_{self.location_grouping}_id\"\n",
    "        node_2 = f\"facility_{self.location_grouping}_id\"\n",
    "        node_3 = f\"destination_{self.location_grouping}_id\"\n",
    "\n",
    "        network_graph = add_nodes_given_df(network_graph, an_inbound_df, [node_1, 'facility_id']) \n",
    "        network_graph = add_nodes_given_df(network_graph, an_outbound_df, ['facility_id', node_2, node_3]) \n",
    "\n",
    "        network_graph = add_edges_given_graph(network_graph, an_inbound_df, an_outbound_df, self.location_grouping)\n",
    "        \n",
    "        # update the variables \n",
    "        self.network = network_graph\n",
    "        self.origin_location_list = an_inbound_df[f'origin_{self.location_grouping}_id'].unique()\n",
    "        self.inbound_data, self.outbound_data = an_inbound_df, an_outbound_df\n",
    "        if self.display_progress: print(f\"Current time of the graph: {self.start_date} to {self.end_date}\") \n",
    "        \n",
    "    def move_to_next_week(self): \n",
    "        \"\"\" \n",
    "        Given the new week's inbound and outbound dataframes, \n",
    "        update self.network graph, self.start_date, and self.end_date to a week after current start date and end date \n",
    "        \n",
    "        Args:\n",
    "            next_inbound_df (pd.DataFrame): new week's inbound dataframe\n",
    "            next_outbound_df (pd.DataFrame): new week's outbound dataframe\n",
    "            display_progress (boolean): whether to display the progress of the function or not\n",
    "        \"\"\"\n",
    "        # update the dates, pull new week's data, & store some informations\n",
    "        self.start_date, self.end_date = self.start_date + timedelta(days=7), self.end_date + timedelta(days=7)\n",
    "        date = self.start_date.strftime(\"%Y-%m-%d\") + \"_\" + self.end_date.strftime(\"%Y-%m-%d\")\n",
    "        next_inbound_df, next_outbound_df = pd.read_csv(f\"../inbound_data/inbound_data_{date}.csv\"), pd.read_csv(f\"../outbound_data/outbound_data_{date}.csv\")\n",
    "        next_inbound_df.load_date, next_outbound_df.load_date = pd.to_datetime(next_inbound_df.load_date), pd.to_datetime(next_outbound_df.load_date)\n",
    "        for colin, colout in zip(next_inbound_df.columns, next_outbound_df.columns): \n",
    "            if colin not in [\"total_loads\", \"load_date\"]: \n",
    "                next_inbound_df[colin] = next_inbound_df[colin].astype(str)\n",
    "            if colout not in [\"total_loads\", \"load_date\"]:\n",
    "                next_outbound_df[colout] = next_outbound_df[colout].astype(str)\n",
    "\n",
    "        # next_inbound_df.to_csv(f\"data/inbound_data_{self.start_date}_{self.end_date}.csv\", index=False)\n",
    "        # next_outbound_df.to_csv(f\"data/outbound_data_{self.start_date}_{self.end_date}.csv\", index=False)\n",
    "\n",
    "        ## if not len(next_inbound_df) and not len(next_outbound_df): \n",
    "        curr_nodes, curr_edges = set(self.network.nodes()), list(self.network.edges(data=True, keys=True)) # needed for efficient removal of nodes & edges\n",
    "        \n",
    "        node_1 = f\"origin_{self.location_grouping}_id\"\n",
    "        node_2 = f\"facility_{self.location_grouping}_id\"\n",
    "        node_3 = f\"destination_{self.location_grouping}_id\"\n",
    "\n",
    "        # or statement is used to check if either inbound or outbound df exists, \n",
    "        # so we can add any final delivery data to the graph\n",
    "        if len(next_inbound_df) or len(next_outbound_df): \n",
    "            # add new nodes \n",
    "            new_nodes = set()\n",
    "            if len(next_inbound_df): new_nodes = set(next_inbound_df[[node_1, 'facility_id']].to_numpy().flatten())\n",
    "            if len(next_outbound_df): new_nodes.union(set(next_outbound_df[[node_2, node_3, 'facility_id']].to_numpy().flatten()))\n",
    "            new_nodes = new_nodes.difference(curr_nodes)\n",
    "            self.network.add_nodes_from(new_nodes)\n",
    "\n",
    "            # add new edges\n",
    "            self.network = add_edges_given_graph(self.network, next_inbound_df, next_outbound_df, self.location_grouping)\n",
    "\n",
    "        # remove old edges\n",
    "        past_edges = []\n",
    "        for edge in curr_edges: \n",
    "            if edge[2] < to_integer(self.start_date): \n",
    "                self.network.remove_edge(edge[0], edge[1], edge[2])\n",
    "                past_edges.append(edge)\n",
    "\n",
    "        # remove isolated nodes\n",
    "        isolated_nodes = list(nx.isolates(self.network))\n",
    "        self.network.remove_nodes_from(isolated_nodes)\n",
    "        \n",
    "        # update variables\n",
    "        self.network.graph['start_date']= self.start_date\n",
    "        self.network.graph['end_date']= self.end_date\n",
    "        self.inbound_data, self.outbound_data = next_inbound_df, next_outbound_df\n",
    "        if self.location_grouping == 'kma': self.origin_location_list = list(set([x.split(\" \")[0] for x in self.network.nodes() if len(x) == 6])) \n",
    "        else: self.origin_location_list = list(set([x.split(\" \")[0] for x in self.network.nodes() if len(x) == 3]))\n",
    "        \n",
    "        if self.display_progress: print(f\"Current time of the graph: {self.start_date} to {self.end_date}\")  \n",
    "\n",
    "    def print_network_information(self, given_network, print_network_time=False): \n",
    "        \"\"\"\n",
    "        Given a network, print out the information of the network\n",
    "        Args: \n",
    "            given_network (nx.MultiDiGraph): a network graph\n",
    "        Returns: N/A\n",
    "        \"\"\"\n",
    "        print(\"---------------------------------------------------------------------------------------------\") \n",
    "        print(given_network)\n",
    "        print(f\"Is the given network a DAG for load_network?: {nx.is_directed_acyclic_graph(given_network)}\")\n",
    "        print(f\"Number of self loops: {nx.number_of_selfloops(given_network)}\")\n",
    "        if print_network_time: print(f\"Current time of the graph: {given_network.graph['start_date']} to {given_network.graph['end_date']}\")\n",
    "        else: print(f\"Current time of the graph: {self.start_date} to {self.end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_Finder():\n",
    "    def __init__(self, location_grouping='kma', origin_location_list=None, network = None):\n",
    "        self.network=network\n",
    "        self.processed_network=None\n",
    "        self.processed=False \n",
    "        self.origin_location_list=origin_location_list\n",
    "        self.match_failure = None\n",
    "        self.remove_failure = 0\n",
    "        self.location_grouping=location_grouping\n",
    "        \n",
    "    def group_to_DiGraph(self, display_progress = False):\n",
    "        \"\"\"\n",
    "        #TODO: explain why aggregate_faciility_zip then group_to_DiGraph (kma-> facility_zip -> kma to kma->kma->kma, aggregate to faciliy KMA)\n",
    "        Assuming that self.network is constructed, \n",
    "        sums the edge weights for edges with the same nodes in self.network variable and \n",
    "        stores the new graph with aggregated edges in self.processed_network variable and returns False if successful \n",
    "\n",
    "        Args:\n",
    "            display_progress (boolean): whether to display the progress of the function or not\n",
    "\n",
    "        NOTE) disregards temporal factor \n",
    "        \"\"\"\n",
    "        if not self.network: \n",
    "            print(\"Please construct the network first\")\n",
    "            return None \n",
    "            \n",
    "        new_name = self.network.name + \" reduced\"\n",
    "        self.processed_network = nx.DiGraph(name=new_name)\n",
    "        self.processed_network.add_nodes_from(self.network)\n",
    "\n",
    "        if display_progress: print(\"Aggregating nodes by KMA...\")\n",
    "        for n1, n2 in self.network.edges():\n",
    "            sum = 0 \n",
    "            for inner_dict in self.network.get_edge_data(n1, n2).values(): \n",
    "                sum += inner_dict['capacity']\n",
    "            self.processed_network.add_edge(n1, n2, capacity = sum)\n",
    "        \n",
    "        nx.set_edge_attributes(self.processed_network, to_integer(self.network.graph['end_date']), 'time')\n",
    "        self.processed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CM_Time(): \n",
    "    def __init__(self, location_grouping='kma', origin=None, facility_id=None, intermediate=None): \n",
    "        self.start_date=None\n",
    "        self.end_date=None\n",
    "        self.cm_network = None   \n",
    "        self.cm_finder = None\n",
    "        self.origin=origin\n",
    "        self.facility_id=facility_id\n",
    "        self.intermediate=intermediate\n",
    "        self.location_grouping = location_grouping\n",
    "        self.weekly_graphs = {}\n",
    "    \n",
    "    def update_dates(self): \n",
    "        \"\"\"\n",
    "        Updates the start and end date by 7 days\n",
    "        \"\"\" \n",
    "        self.start_date += timedelta(days=7)\n",
    "        self.end_date += timedelta(days=7)\n",
    "\n",
    "    def construct_or_update_tg(self, filter_key='load_count', display_progress=False, display_path_info=False):\n",
    "        \"\"\" \n",
    "        Either (1) creates a network graph given a start and end date \n",
    "            or (2) updates the network graph to the next week's graph \n",
    "\n",
    "        Args: \n",
    "            start_date, end_date: start & end date of the first two weeks of the simulation\n",
    "\n",
    "        Returns: n/a\n",
    "        \"\"\"        \n",
    "        # construct or update cm_finder.network \n",
    "        if not self.cm_network: \n",
    "            self.cm_network = temporalNetwork(self.start_date, self.end_date, display_progress, self.location_grouping, self.origin, self.facility_id, self.intermediate)\n",
    "            self.cm_network.construct_network_graph()\n",
    "            self.cm_finder = CM_Finder(location_grouping=self.location_grouping)\n",
    "        else: \n",
    "            self.cm_network.move_to_next_week()\n",
    "\n",
    "        self.cm_finder.origin_location_list = self.cm_network.origin_location_list\n",
    "        self.cm_finder.network = self.cm_network.network\n",
    "        \n",
    "        # self.cm_finder.group_to_DiGraph(display_progress = display_progress)\n",
    "        self.weekly_graphs[self.end_date] = self.cm_finder.network\n",
    "\n",
    "    def temporal_query(self, start_date, temporal=True, looback = 7, number_of_weeks=None, termination_date = None, \\\n",
    "                    filter_key = \"load_count\", display_progress=False, display_path_info = False): \n",
    "        \"\"\"\n",
    "        Given a start date, run the simulation for number_of_weeks or until termination_date is reached.\n",
    "\n",
    "        Args: \n",
    "            start_date: start date of the first week of the simulation\n",
    "            temporal: if True, run the simulation for every two weeks, if False, run the simulation from start_date until end_date\n",
    "            number_of_weeks: number of weeks to run the simulation for\n",
    "            termination_date: date to stop the simulation\n",
    "            filter_key: key to filter the network on (load_count or path_score)\n",
    "            display_progress: if True, display progress bar\n",
    "            display_path_info: if True, display path info\n",
    "\n",
    "        Returns: a dictionary of simulation result for each week\n",
    "            \n",
    "        Note:\n",
    "        * termination_date: termination date of the entire analysis, when end_date reaches termination_date, the query loop terminates,\n",
    "        * end_date: the end date of the two-week window, will be updated every week\n",
    "\n",
    "        - Once the parameters (location_grouping, origin, facility_id, intermediate) are used to initialise the cm_time class, \n",
    "          they will be used for any further analysis until new initialisation happens.\n",
    "          query_weekly method will only perform analysis, no alterations can be made by calling solely this.\n",
    "\n",
    "        - If temporal=True, --> end_date != termination_date, eventually at the end of simulations, end_date = termination_date\n",
    "            and number_of_weeks is given, end_date = start_date + 13 days for the first simulation, termination_date = start_date + 7 days * number_of_weeks\n",
    "            and termination_date is given, end_date = start_date + 13 days for the first simulation and termination_date=termination_date for the simulation\n",
    "          If temporal=False --> end_date = termination_date \n",
    "            and number_of_weeks is given, end_date = start_date + 7 days * number_of_weeks for the simulation \n",
    "            and termination_date is given, end_date=termination_date for the simulation\n",
    "\n",
    "        * simulation_results: a dictionary with key as the end_date and value as the simulation result\n",
    "        \"\"\"\n",
    "\n",
    "        # create information needed for a new query with the given start_date and number_of_weeks\n",
    "        # possible bug when end_date > termination_date.\n",
    "        if temporal: \n",
    "            self.start_date, self.end_date = start_date, start_date + timedelta(days=looback-1)\n",
    "\n",
    "            if number_of_weeks: termination_date = self.start_date + timedelta(days=7) * number_of_weeks\n",
    "            elif termination_date: termination_date = termination_date\n",
    "            else: raise Exception(\"Neither number of weeks nor termination date was given to set the simulation time period.\")\n",
    "        \n",
    "            # run simulation for every two weeks until termination_date\n",
    "            while self.end_date <= termination_date:    \n",
    "                self.construct_or_update_tg(filter_key=filter_key, \\\n",
    "                                    display_progress=display_progress, display_path_info=display_path_info)\n",
    "                self.update_dates() \n",
    "                \n",
    "        else: \n",
    "            if number_of_weeks: self.start_date, self.end_date = start_date, start_date + timedelta(days=7) * number_of_weeks\n",
    "            elif termination_date: self.start_date, self.end_date = start_date, termination_date\n",
    "            else: raise Exception(\"Neither number of weeks nor termination date was given to set the simulation time period.\")\n",
    "            self.run_single_simulation(filter_key=filter_key, \\\n",
    "                                display_progress=display_progress, display_path_info=display_path_info)\n",
    "\n",
    "        return self.weekly_graphs\n",
    "\n",
    "    def if_edge(node1, node2, curr_graph): \n",
    "        adjacency_matrix = curr_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operator_l2(u, v):\n",
    "    return (u - v) ** 2\n",
    "\n",
    "def operator_sub(u, v):\n",
    "    return (u - v)\n",
    "\n",
    "binary_operator = operator_l2\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def link_examples_to_features(link_examples, transform_node):\n",
    "    return [\n",
    "        operator_l2(transform_node(src), transform_node(dst)) for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "def link_examples_to_features_sub(link_examples, transform_node):\n",
    "    return [\n",
    "        operator_sub(transform_node(src), transform_node(dst)) for src, dst in link_examples\n",
    "    ]\n",
    "\n",
    "def link_prediction_classifier(max_iter=2000):\n",
    "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter, penalty=\"l2\") #, solver=\"liblinear\")\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(graph, prediction_window_size=2): \n",
    "    # graph = stellar graph\n",
    "    # identify edges based on dates\n",
    "    edges, weights = np.array(graph.edges(include_edge_weight=True)[0]), np.array(graph.edges(include_edge_weight=True)[1])\n",
    "    lower_lim = sorted(list(set(weights)))[-prediction_window_size]\n",
    "    index_test, index_train = np.where(weights >= lower_lim)[0], np.where(weights < lower_lim)[0]\n",
    "\n",
    "    # create test & train edge sets\n",
    "    test_edges, test_labels = edges[index_test], weights[index_test]\n",
    "    train_edges, train_labels = edges[index_train], weights[index_train]\n",
    "    test_weighted_edges = np.rec.fromarrays([test_edges[:,0], test_edges[:,1], test_labels])\n",
    "    train_weighted_edges = np.rec.fromarrays([train_edges[:,0], train_edges[:,1], train_labels])\n",
    "    # print(set(test_labels), set(train_labels))\n",
    "\n",
    "    # create test and train graph \n",
    "    test_graph,train_graph = nx.MultiDiGraph(), nx.MultiDiGraph()\n",
    "    test_graph.add_weighted_edges_from(test_weighted_edges,weight='time')\n",
    "    train_graph.add_weighted_edges_from(train_weighted_edges,weight='time')\n",
    "    test_graph, train_graph = StellarGraph.from_networkx(test_graph, edge_weight_attr='time', edge_type_attr='directed'), \\\n",
    "                        StellarGraph.from_networkx(train_graph, edge_weight_attr='time', edge_type_attr='directed'), \n",
    "\n",
    "    # create pos & neg edges \n",
    "    edge_splitter_test = EdgeSplitter(test_graph, graph)\n",
    "    graph_test, examples_test, labels_test = edge_splitter_test.train_test_split( #result_graph, [u, v], edge_data_labels (1 or 0)\n",
    "        p=0.1, method=\"global\",\n",
    "    )\n",
    "\n",
    "    ## train graph \n",
    "    edge_splitter_train = EdgeSplitter(train_graph, graph)\n",
    "    graph_train, examples, labels = edge_splitter_train.train_test_split(\n",
    "        p=0.1, method=\"global\"\n",
    "    )\n",
    "    \n",
    "    # (\n",
    "    #     examples_train,\n",
    "    #     examples_model_selection,\n",
    "    #     labels_train,\n",
    "    #     labels_model_selection,\n",
    "    # ) = sklearn.model_selection.train_test_split(examples, labels, train_size=0.75, test_size=0.25)\n",
    "\n",
    "    # concatenate graph_train and train_graph as by time t, we have learned all previous edges up to t \n",
    "    test_graph_e = graph_test.edges(include_edge_weight=True)\n",
    "    test_graph_edges, test_graph_weights= np.array(test_graph_e[0]),np.array(test_graph_e[1])\n",
    "    test_weighted_edges = np.rec.fromarrays([test_graph_edges[:,0], test_graph_edges[:,1], test_graph_weights])\n",
    "    train_graph_e = train_graph.edges(include_edge_weight=True)\n",
    "    train_graph_edges, train_graph_weights= np.array(train_graph_e[0]),np.array(train_graph_e[1])\n",
    "    train_weighted_edges = np.rec.fromarrays([train_graph_edges[:,0], train_graph_edges[:,1], train_graph_weights])\n",
    "    union_graph_test = nx.MultiDiGraph()\n",
    "    union_graph_test.add_weighted_edges_from(test_weighted_edges)\n",
    "    union_graph_test.add_weighted_edges_from(train_weighted_edges)\n",
    "    union_graph_test = StellarGraph.from_networkx(union_graph_test, edge_weight_attr='time', edge_type_attr='directed')\n",
    "\n",
    "    if set(graph_train.edges(include_edge_weight=True)[1]).intersection(set(graph_test.edges(include_edge_weight=True)[1])): \n",
    "        raise(Exception)\n",
    "    return union_graph_test, graph_test, examples_test, labels_test, graph_train, examples, labels #, examples_train,examples_model_selection,labels_train,labels_model_selection,\n",
    "\n",
    "# union_graph_test, graph_test, examples_test, labels_test, graph_train, examples, labels = data_split(graph)\n",
    "# print(len(graph_test.edges()), len(graph_train.edges()))\n",
    "# print(set(graph_train.edges(include_edge_weight=True)[1]).intersection(set(graph_test.edges(include_edge_weight=True)[1])))\n",
    "# graph_test, examples_test, labels_test, graph_train, examples, labels, examples_train,examples_model_selection,labels_train,labels_model_selection, = data_split(graph)\n",
    "\n",
    "def temporal_model(graph, num_walks_per_node=10, walk_length = 10, context_window_size = 2): \n",
    "    num_cw = len(graph.nodes()) * num_walks_per_node * (walk_length - context_window_size + 1)\n",
    "    temporal_rw = TemporalRandomWalk(graph)\n",
    "    temporal_walks = temporal_rw.run(\n",
    "        num_cw=num_cw,\n",
    "        cw_size=context_window_size,\n",
    "        max_walk_length=walk_length,\n",
    "        walk_bias=\"exponential\",\n",
    "    )\n",
    "    \n",
    "    embedding_size = 128\n",
    "    temporal_model = Word2Vec(\n",
    "        temporal_walks,\n",
    "        vector_size=embedding_size,\n",
    "        window=context_window_size,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=2,\n",
    "        epochs=1,)\n",
    "\n",
    "    unseen_node_embedding = np.zeros(embedding_size)\n",
    "\n",
    "    def temporal_embedding(u):\n",
    "        try:\n",
    "            return temporal_model.wv[u]\n",
    "        except KeyError:\n",
    "            return unseen_node_embedding\n",
    "    return temporal_embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalPrediction():\n",
    "    def __init__(self, num_walks_per_node=10, walk_length = 10, context_window_size = 2):\n",
    "        self.num_walks_per_node = num_walks_per_node\n",
    "        self.walk_length = walk_length\n",
    "        self.context_window_size = context_window_size\n",
    "        self.curr_regret = 0\n",
    "        self.regrets = []\n",
    "        self.curr_false_positive_set = set()\n",
    "        self.train_errors = [] \n",
    "        self.test_errors = []\n",
    "\n",
    "    def fit_classifier(self, graph, examples, labels):\n",
    "        temporal_embedding = temporal_model(graph)\n",
    "        temporal_link_features = link_examples_to_features(examples, temporal_embedding)\n",
    "        temporal_clf = link_prediction_classifier()\n",
    "        temporal_clf.fit(temporal_link_features, labels)\n",
    "        return temporal_clf\n",
    "\n",
    "    def evaluate_score(self, clf, link_features, link_labels, return_idces=False):\n",
    "        predicted = clf.predict_proba(link_features)\n",
    "        positive_column = list(clf.classes_).index(1)\n",
    "        if return_idces: \n",
    "            false_positive_idces = np.where((link_labels == 0) & (predicted[:, positive_column] > 0.5))[0]\n",
    "            # true_positive_idces = np.where((link_labels == 1) & (predicted[:, positive_column] > 0.5))[0]\n",
    "            return roc_auc_score(link_labels, predicted[:, positive_column]), false_positive_idces #, true_positive_idces\n",
    "        return roc_auc_score(link_labels, predicted[:, positive_column])\n",
    "\n",
    "    def update_curr_false_positive(self, new_edge_set): \n",
    "        if self.curr_false_positive_set.intersection(new_edge_set): \n",
    "            self.curr_false_positive_set = self.curr_false_positive_set - new_edge_set\n",
    "            print(f\"New Reduced Regret: {len(self.curr_false_positive_set)}\")\n",
    "\n",
    "    def run_granular_analysis(self, graph, display_progress=False): \n",
    "        # update regret by checking if they are in the new graph \n",
    "        self.update_curr_false_positive(set(graph.edges()))\n",
    "\n",
    "        # convert to stellargraph & split data\n",
    "        graph = StellarGraph.from_networkx(graph, edge_weight_attr='time', edge_type_attr='directed')\n",
    "        union_graph_test, graph_test, examples_test, labels_test, graph_train, examples, labels = data_split(graph)\n",
    "        temporal_embedding = temporal_model(graph_train, \\\n",
    "                                            num_walks_per_node=self.num_walks_per_node, walk_length=self.walk_length, \\\n",
    "                                            context_window_size=self.context_window_size)\n",
    "        # fit & learn \n",
    "        temporal_clf = self.fit_classifier(graph_train, examples, labels)\n",
    "        temporal_link_features = link_examples_to_features(examples, temporal_embedding)\n",
    "        temporal_score_train = self.evaluate_score(temporal_clf, temporal_link_features, labels)\n",
    "        self.train_errors.append(temporal_score_train)\n",
    "        if display_progress: print(f\"Temporal Training Score (ROC AUC): {temporal_score_train:.2f}\")\n",
    "\n",
    "        # random walk on the test graph + train_graph & calculate test score\n",
    "        temporal_embedding = temporal_model(union_graph_test, \\\n",
    "                                            num_walks_per_node=self.num_walks_per_node, walk_length=self.walk_length, \\\n",
    "                                            context_window_size=self.context_window_size)\n",
    "        temporal_link_features_test = link_examples_to_features(examples_test, temporal_embedding)\n",
    "        temporal_score_test, false_positive_idces = self.evaluate_score(temporal_clf, temporal_link_features_test, labels_test, return_idces=True)\n",
    "        false_positive_edges = [examples_test[i] for i in false_positive_idces]\n",
    "        self.test_errors.append(temporal_score_test)\n",
    "        if display_progress: print(f\"Temporal Test Score (ROC AUC): {temporal_score_test:.2f}\")\n",
    "\n",
    "        # update regret by adding new false_positive_edges \n",
    "        if false_positive_edges: \n",
    "            false_positive_edges = set([tuple(x) for x in false_positive_edges])\n",
    "            print(f\"New False Positives: {len(false_positive_edges - self.curr_false_positive_set)}\")\n",
    "            self.curr_false_positive_set = self.curr_false_positive_set.union(set(false_positive_edges))\n",
    "            self.curr_regret = len(self.curr_false_positive_set)\n",
    "\n",
    "        self.regrets.append(self.curr_regret)\n",
    "\n",
    "    def print_current_info(self, curr_time): \n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(f\"Current Week: {curr_time}\")\n",
    "        print(f\"training error: {np.round(self.train_errors[-1],2)}, test error: {np.round(self.test_errors[-1],2)}\")\n",
    "        print(f\"Current Regret: {self.curr_regret}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "    def graph(self, time_range, graph_errors = True, graph_regret = False, title=None): \n",
    "        n = min(len(self.train_errors), len(self.test_errors))\n",
    "        if title: plt.title(title)\n",
    "        if graph_errors: \n",
    "            plt.plot(time_range[:n], self.train_errors[:n], label='train')\n",
    "            plt.plot(time_range[:n], self.test_errors[:n], label='test')\n",
    "        if graph_regret: \n",
    "            plt.plot(time_range[:n], self.curr_regret[:n], label='regret')\n",
    "        plt.legend() \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = len(lp.train_errors)\n",
    "# time = list(weekly_graphs.keys())[:n-1]\n",
    "# plt.title(\"hello\")\n",
    "# plt.plot(time, lp.train_errors[:-1], label='train')\n",
    "# plt.plot(time, lp.test_errors, label='test')\n",
    "# plt.tight_layout()\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_time = CM_Time(location_grouping = 'zip3') \n",
    "weekly_graphs = cm_time.temporal_query(start_date=datetime(2021,1,1).date(), looback=7, termination_date= datetime(2023,6, 1).date(), \\\n",
    "                    display_progress=False, display_path_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/126 [00:29<1:00:50, 29.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 62\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-01-07\n",
      "training error: 0.72, test error: 0.79\n",
      "Current Regret: 62\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/126 [01:00<1:03:08, 30.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 50\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-01-14\n",
      "training error: 0.72, test error: 0.81\n",
      "Current Regret: 112\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/126 [01:31<1:02:38, 30.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 68\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-01-21\n",
      "training error: 0.56, test error: 0.77\n",
      "Current Regret: 180\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/126 [02:01<1:02:11, 30.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 61\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-01-28\n",
      "training error: 0.75, test error: 0.77\n",
      "Current Regret: 241\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/126 [02:36<1:04:49, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 89\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-02-04\n",
      "training error: 0.34, test error: 0.77\n",
      "Current Regret: 330\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/126 [03:06<1:02:30, 31.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 61\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-02-11\n",
      "training error: 0.72, test error: 0.78\n",
      "Current Regret: 391\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 7/126 [03:33<59:39, 30.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 56\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-02-18\n",
      "training error: 0.73, test error: 0.81\n",
      "Current Regret: 447\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 8/126 [04:01<57:38, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 67\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-02-25\n",
      "training error: 0.74, test error: 0.84\n",
      "Current Regret: 514\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9/126 [04:29<56:32, 28.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 69\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-03-04\n",
      "training error: 0.72, test error: 0.76\n",
      "Current Regret: 583\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/126 [05:02<58:00, 30.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 17\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-03-11\n",
      "training error: 0.74, test error: 0.83\n",
      "Current Regret: 600\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 11/126 [05:29<55:56, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 2\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-03-18\n",
      "training error: 0.52, test error: 0.3\n",
      "Current Regret: 602\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 12/126 [05:55<53:29, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 85\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-03-25\n",
      "training error: 0.75, test error: 0.79\n",
      "Current Regret: 687\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 13/126 [06:19<51:00, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 60\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-04-01\n",
      "training error: 0.73, test error: 0.73\n",
      "Current Regret: 747\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 14/126 [06:44<49:20, 26.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 15\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-04-08\n",
      "training error: 0.72, test error: 0.56\n",
      "Current Regret: 762\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 15/126 [07:09<47:59, 25.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 61\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-04-15\n",
      "training error: 0.75, test error: 0.81\n",
      "Current Regret: 823\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 16/126 [07:34<46:49, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 41\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-04-22\n",
      "training error: 0.64, test error: 0.78\n",
      "Current Regret: 864\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 17/126 [07:59<46:08, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 28\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-04-29\n",
      "training error: 0.67, test error: 0.7\n",
      "Current Regret: 892\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 18/126 [08:23<45:14, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 23\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-05-06\n",
      "training error: 0.72, test error: 0.79\n",
      "Current Regret: 915\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 19/126 [08:48<44:46, 25.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 5\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-05-13\n",
      "training error: 0.74, test error: 0.55\n",
      "Current Regret: 920\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 20/126 [09:13<44:16, 25.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 75\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-05-20\n",
      "training error: 0.75, test error: 0.81\n",
      "Current Regret: 995\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 21/126 [09:38<43:33, 24.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 36\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-05-27\n",
      "training error: 0.73, test error: 0.8\n",
      "Current Regret: 1031\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 22/126 [10:03<43:27, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 40\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-06-03\n",
      "training error: 0.74, test error: 0.75\n",
      "Current Regret: 1071\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 23/126 [10:28<42:50, 24.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 39\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-06-10\n",
      "training error: 0.53, test error: 0.74\n",
      "Current Regret: 1110\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 24/126 [10:53<42:17, 24.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 55\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-06-17\n",
      "training error: 0.77, test error: 0.78\n",
      "Current Regret: 1165\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 25/126 [11:18<41:54, 24.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 55\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-06-24\n",
      "training error: 0.75, test error: 0.81\n",
      "Current Regret: 1220\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 26/126 [11:42<41:22, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 44\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-07-01\n",
      "training error: 0.72, test error: 0.81\n",
      "Current Regret: 1264\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 27/126 [12:07<41:00, 24.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 36\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-07-08\n",
      "training error: 0.72, test error: 0.77\n",
      "Current Regret: 1300\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 28/126 [12:32<40:34, 24.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 70\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-07-15\n",
      "training error: 0.74, test error: 0.79\n",
      "Current Regret: 1370\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 29/126 [12:57<39:59, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 22\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-07-22\n",
      "training error: 0.34, test error: 0.68\n",
      "Current Regret: 1392\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 30/126 [13:22<39:45, 24.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 62\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-07-29\n",
      "training error: 0.73, test error: 0.79\n",
      "Current Regret: 1454\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 31/126 [13:47<39:25, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 51\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-08-05\n",
      "training error: 0.75, test error: 0.82\n",
      "Current Regret: 1505\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 32/126 [14:12<39:00, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 43\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-08-12\n",
      "training error: 0.76, test error: 0.77\n",
      "Current Regret: 1548\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 33/126 [14:36<38:24, 24.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 40\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-08-19\n",
      "training error: 0.75, test error: 0.74\n",
      "Current Regret: 1588\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 34/126 [15:01<38:02, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 50\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-08-26\n",
      "training error: 0.68, test error: 0.78\n",
      "Current Regret: 1638\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 35/126 [15:26<37:51, 24.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 17\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-09-02\n",
      "training error: 0.75, test error: 0.78\n",
      "Current Regret: 1655\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 36/126 [15:51<37:31, 25.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 21\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-09-09\n",
      "training error: 0.75, test error: 0.66\n",
      "Current Regret: 1676\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 37/126 [16:16<37:01, 24.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 40\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-09-16\n",
      "training error: 0.73, test error: 0.76\n",
      "Current Regret: 1716\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 38/126 [16:41<36:32, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 48\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-09-23\n",
      "training error: 0.31, test error: 0.75\n",
      "Current Regret: 1764\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 39/126 [17:05<35:53, 24.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 58\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-09-30\n",
      "training error: 0.57, test error: 0.73\n",
      "Current Regret: 1822\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 40/126 [17:32<36:16, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 59\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-10-07\n",
      "training error: 0.7, test error: 0.79\n",
      "Current Regret: 1881\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 41/126 [17:57<35:37, 25.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New False Positives: 54\n",
      "--------------------------------------------------\n",
      "Current Week: 2021-10-14\n",
      "training error: 0.76, test error: 0.82\n",
      "Current Regret: 1935\n",
      "--------------------------------------------------\n",
      "** Sampled 175 positive and 175 negative edges. **\n",
      "** Sampled 427 positive and 427 negative edges. **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 41/126 [18:19<37:58, 26.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m lp \u001b[38;5;241m=\u001b[39m TemporalPrediction()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time, graph \u001b[38;5;129;01min\u001b[39;00m tqdm(weekly_graphs\u001b[38;5;241m.\u001b[39mitems()): \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_granular_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     lp\u001b[38;5;241m.\u001b[39mprint_current_info(time)\n",
      "Cell \u001b[0;32mIn[143], line 50\u001b[0m, in \u001b[0;36mTemporalPrediction.run_granular_analysis\u001b[0;34m(self, graph, display_progress)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_progress: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemporal Training Score (ROC AUC): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemporal_score_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# random walk on the test graph + train_graph & calculate test score\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m temporal_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43munion_graph_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnum_walks_per_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_walks_per_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcontext_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_window_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m temporal_link_features_test \u001b[38;5;241m=\u001b[39m link_examples_to_features(examples_test, temporal_embedding)\n\u001b[1;32m     54\u001b[0m temporal_score_test, false_positive_idces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_score(temporal_clf, temporal_link_features_test, labels_test, return_idces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[29], line 65\u001b[0m, in \u001b[0;36mtemporal_model\u001b[0;34m(graph, num_walks_per_node, walk_length, context_window_size)\u001b[0m\n\u001b[1;32m     63\u001b[0m num_cw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(graph\u001b[38;5;241m.\u001b[39mnodes()) \u001b[38;5;241m*\u001b[39m num_walks_per_node \u001b[38;5;241m*\u001b[39m (walk_length \u001b[38;5;241m-\u001b[39m context_window_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m temporal_rw \u001b[38;5;241m=\u001b[39m TemporalRandomWalk(graph)\n\u001b[0;32m---> 65\u001b[0m temporal_walks \u001b[38;5;241m=\u001b[39m \u001b[43mtemporal_rw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_cw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_cw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcw_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_walk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwalk_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalk_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexponential\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m embedding_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m     73\u001b[0m temporal_model \u001b[38;5;241m=\u001b[39m Word2Vec(\n\u001b[1;32m     74\u001b[0m     temporal_walks,\n\u001b[1;32m     75\u001b[0m     vector_size\u001b[38;5;241m=\u001b[39membedding_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     80\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/stellargraph/data/explorer.py:1116\u001b[0m, in \u001b[0;36mTemporalRandomWalk.run\u001b[0;34m(self, num_cw, cw_size, max_walk_length, initial_edge_bias, walk_bias, p_walk_success_threshold, seed)\u001b[0m\n\u001b[1;32m   1112\u001b[0m t \u001b[38;5;241m=\u001b[39m times[first_edge_index]\n\u001b[1;32m   1114\u001b[0m remaining_length \u001b[38;5;241m=\u001b[39m num_cw \u001b[38;5;241m-\u001b[39m num_cw_curr \u001b[38;5;241m+\u001b[39m cw_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1116\u001b[0m walk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_walk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_walk_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwalk_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp_rs\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(walk) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cw_size:\n\u001b[1;32m   1120\u001b[0m     walks\u001b[38;5;241m.\u001b[39mappend(walk)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/stellargraph/data/explorer.py:1183\u001b[0m, in \u001b[0;36mTemporalRandomWalk._walk\u001b[0;34m(self, src, dst, t, length, bias_type, np_rs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m node, time \u001b[38;5;241m=\u001b[39m dst, t\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m-> 1183\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp_rs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp_rs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m         node, time \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/stellargraph/data/explorer.py:1164\u001b[0m, in \u001b[0;36mTemporalRandomWalk._step\u001b[0;34m(self, node, time, bias_type, np_rs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, time, bias_type, np_rs):\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m    Perform 1 temporal step from a node. Returns None if a dead-end is reached.\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m \n\u001b[1;32m   1163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m     neighbours, times \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_edge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m     neighbours \u001b[38;5;241m=\u001b[39m neighbours[times \u001b[38;5;241m>\u001b[39m time]\n\u001b[1;32m   1166\u001b[0m     times \u001b[38;5;241m=\u001b[39m times[times \u001b[38;5;241m>\u001b[39m time]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/stellargraph/core/graph.py:790\u001b[0m, in \u001b[0;36mStellarGraph.neighbor_arrays\u001b[0;34m(self, node, include_edge_weight, edge_types, use_ilocs)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03mObtains the collection of neighbouring nodes connected to the given node\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03mas an array of node_ids. If `include_edge_weight` edge is `True` then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;124;03m    of edge weights is also returned in a tuple `(neighbor_array, edge_weight_array)`\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_ilocs:\n\u001b[0;32m--> 790\u001b[0m     node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nodes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_iloc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    792\u001b[0m edge_ilocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edges\u001b[38;5;241m.\u001b[39medge_ilocs(node, ins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, outs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    793\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edges\u001b[38;5;241m.\u001b[39msources[edge_ilocs]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/stellargraph/core/element_data.py:95\u001b[0m, in \u001b[0;36mExternalIdIndex.to_iloc\u001b[0;34m(self, ids, smaller_type, strict)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_iloc\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, smaller_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Convert external IDs ``ids`` to integer locations.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        smaller_type is False)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     internal_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_valid(ids, internal_ids)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3486\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pself \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m ptarget \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target:\n\u001b[1;32m   3482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pself\u001b[38;5;241m.\u001b[39mget_indexer(\n\u001b[1;32m   3483\u001b[0m         ptarget, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[1;32m   3484\u001b[0m     )\n\u001b[0;32m-> 3486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py38_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3512\u001b[0m, in \u001b[0;36mIndex._get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3510\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_nearest_indexer(target, limit, tolerance)\n\u001b[1;32m   3511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3512\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_engine_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ensure_platform_int(indexer)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lp = TemporalPrediction()\n",
    "for time, graph in tqdm(weekly_graphs.items()): \n",
    "    lp.run_granular_analysis(graph)\n",
    "    # lp.print_current_info(time)\n",
    "\n",
    "lp.graph_errors(list(weekly_graphs.keys()), title=\"Temporal Prediction Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for edge in false_positive_edges: \n",
    "#     if graph.has_edge(edge[0], edge[1]): print(f\"false_positive returned but is true positive: {edge}\")\n",
    "# for edge in true_positive_edges: \n",
    "#     if not graph.has_edge(edge[0], edge[1]): print(f\"true positive returned but is false positive: {edge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [np.array(['273', '604'], dtype=object), np.array(['664', '973'], dtype=object), np.array(['142', '806'], dtype=object), np.array(['981', '475'], dtype=object), np.array(['744', '20'], dtype=object), np.array(['28', '115'], dtype=object), np.array(['18', '268'], dtype=object)]\n",
    "print(test)\n",
    "print(set([tuple(x) for x in test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
